{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1l2XaPAtMQY8PbzxvH62sBzNWJlim9jPP",
      "authorship_tag": "ABX9TyPU1wTXzozhEXZ9uacN+3o6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FieryCatalyst/ML-Models/blob/main/Premier_League_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Premier Leauge Prediction Model Training\n",
        "Training the PL prediction model by using the historical data present from 1993 to 2024 seasons\n",
        "\n"
      ],
      "metadata": {
        "id": "2f6C0WGpk5in"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J46UY4eyQAJV",
        "outputId": "32b609f9-9f7d-4ca2-c595-865c8c103200"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib\n",
        "import numpy as np\n",
        "import shutil # Import shutil for directory operations\n",
        "\n",
        "# ===== Load football-data.co.uk CSV (historical) =====\n",
        "def load_historical_csv(directory_path=\"/content/football data\"):\n",
        "    all_files = os.listdir(directory_path)\n",
        "    csv_files = [os.path.join(directory_path, f) for f in all_files if f.endswith('.csv')]\n",
        "\n",
        "    if not csv_files:\n",
        "        print(f\"No CSV files found in {directory_path}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    all_dataframes = []\n",
        "    for csv_file in csv_files:\n",
        "        try:\n",
        "            # Read with error handling and low memory\n",
        "            df = pd.read_csv(csv_file, encoding=\"latin1\", low_memory=False, on_bad_lines='skip')\n",
        "            all_dataframes.append(df)\n",
        "            print(f\"Loaded {os.path.basename(csv_file)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {csv_file}: {e}\")\n",
        "\n",
        "    if all_dataframes:\n",
        "        combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
        "        combined_df = combined_df.rename(columns=lambda x: x.strip())\n",
        "        print(\"✅ All historical CSV files combined.\")\n",
        "        return combined_df\n",
        "    else:\n",
        "        print(\"❌ No historical data could be loaded.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# ===== Create target =====\n",
        "def create_target(df):\n",
        "    print(\"ℹ️ Columns available in create_target:\", df.columns.tolist()) # Debug print\n",
        "\n",
        "    # Use the goals from historical data (lowercase column names after standardization)\n",
        "    if \"fthg\" in df.columns and \"ftag\" in df.columns:\n",
        "        df[\"result\"] = df.apply(\n",
        "            lambda row: 1 if row[\"fthg\"] > row[\"ftag\"]\n",
        "                        else (-1 if row[\"fthg\"] < row[\"ftag\"] else 0),\n",
        "            axis=1\n",
        "        )\n",
        "        print(\"✅ Target variable 'result' created based on historical data.\")\n",
        "    else:\n",
        "        print(\"❌ Could not create target variable: Historical goal columns (fthg, ftag) not found after standardization.\")\n",
        "        df[\"result\"] = np.nan # Or handle appropriately\n",
        "\n",
        "    return df\n",
        "\n",
        "# ===== Feature Engineering (Simplified) =====\n",
        "def add_features(df):\n",
        "    print(\"ℹ️ Columns available in add_features:\", df.columns.tolist()) # Debug print\n",
        "\n",
        "    # Use lowercase column names for goal calculations after standardization\n",
        "    home_goals_col = \"fthg\"\n",
        "    away_goals_col = \"ftag\"\n",
        "\n",
        "    if home_goals_col not in df.columns or away_goals_col not in df.columns:\n",
        "         print(\"❌ Could not find suitable goal columns for feature engineering after standardization.\")\n",
        "         return df # Return DataFrame without adding features if goal columns are missing\n",
        "\n",
        "    print(f\"ℹ️ Using '{home_goals_col}' and '{away_goals_col}' for goal calculations.\")\n",
        "\n",
        "    # Use historical goals for goal difference calculation\n",
        "    df[\"home_goal_diff\"] = df[home_goals_col] - df[away_goals_col]\n",
        "    df[\"away_goal_diff\"] = df[away_goals_col] - df[home_goals_col]\n",
        "    print(\"✅ 'home_goal_diff' and 'away_goal_diff' features created.\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# ===== Train Model (Simplified Feature Set) =====\n",
        "def train_model(df):\n",
        "    print(\"ℹ️ Columns available in train_model:\", df.columns.tolist()) # Debug print\n",
        "\n",
        "    # Select features based on the simplified set (basic historical stats and goal difference)\n",
        "    # Use lowercase column names as standardized in the main block\n",
        "    feature_candidates = {\n",
        "        \"shots\": (\"hs\", \"as\"),\n",
        "        \"shots_on_target\": (\"hst\", \"ast\"),\n",
        "        \"fouls\": (\"hf\", \"af\"),\n",
        "        \"corners\": (\"hc\", \"ac\"),\n",
        "        \"yellows\": (\"hy\", \"ay\"),\n",
        "        \"reds\": (\"hr\", \"ar\"),\n",
        "        \"goal_diff\": (\"home_goal_diff\", \"away_goal_diff\")\n",
        "    }\n",
        "\n",
        "    features = []\n",
        "    for stat_type, cols in feature_candidates.items():\n",
        "        for col in cols:\n",
        "            if col in df.columns and col not in features: # Avoid adding duplicates\n",
        "                 features.append(col)\n",
        "                # Add both home and away if one exists and it's a paired stat (not diff)\n",
        "                 if stat_type not in [\"goal_diff\"]:\n",
        "                     if col.startswith(\"h\"):\n",
        "                         away_col = \"a\" + col[1:] # Replace first 'h' with 'a'\n",
        "                         if away_col in df.columns and away_col not in features:\n",
        "                             features.append(away_col)\n",
        "                     elif col.startswith(\"a\"):\n",
        "                         home_col = \"h\" + col[1:] # Replace first 'a' with 'h'\n",
        "                         if home_col in df.columns and home_col not in features:\n",
        "                             features.append(home_col)\n",
        "            # Special case for goal_diff which is already paired\n",
        "            elif stat_type in [\"goal_diff\"] and col in df.columns and col not in features:\n",
        "                features.append(col)\n",
        "\n",
        "    # Remove goal columns used for the target\n",
        "    features_to_remove = [\"fthg\", \"ftag\"]\n",
        "    features = [f for f in features if f not in features_to_remove]\n",
        "\n",
        "    if not features:\n",
        "        print(\"❌ No suitable features found for training.\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Using features: {features}\")\n",
        "\n",
        "    X = df[features].fillna(0)\n",
        "    y = df[\"result\"]\n",
        "\n",
        "    # Drop rows where result is NaN if create_target failed\n",
        "    valid_indices = y.dropna().index\n",
        "    X = X.loc[valid_indices]\n",
        "    y = y.loc[valid_indices]\n",
        "\n",
        "    if X.empty or y.empty:\n",
        "        print(\"❌ No valid data with target variable to train on.\")\n",
        "        return None\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Randomized hyperparameter search\n",
        "    param_dist = {\n",
        "        \"n_estimators\": [200, 300, 400],\n",
        "        \"max_depth\": [None, 10, 20, 30],\n",
        "        \"min_samples_split\": [2, 5, 10],\n",
        "        \"min_samples_leaf\": [1, 2, 4],\n",
        "        \"max_features\": [\"sqrt\", \"log2\", None],\n",
        "        \"class_weight\": [\"balanced\"]\n",
        "    }\n",
        "    rf = RandomForestClassifier(random_state=42)\n",
        "    clf = RandomizedSearchCV(rf, param_distributions=param_dist,\n",
        "                             n_iter=10, cv=5, n_jobs=-1, scoring=\"accuracy\")\n",
        "    clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "    y_pred = clf.predict(X_test_scaled)\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2%}\")\n",
        "    print(\"\\nClassification Report:\\n\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    os.makedirs(\"models\", exist_ok=True)\n",
        "    joblib.dump(clf.best_estimator_, \"models/premier_league_winner_model.pkl\")\n",
        "    joblib.dump(scaler, \"models/scaler.pkl\")\n",
        "    print(\"✅ Model and scaler saved successfully!\")\n",
        "\n",
        "    return clf.best_estimator_\n",
        "\n",
        "# ===== Main pipeline =====\n",
        "# Ensure the data directory exists\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "os.makedirs(\"/content/football data\", exist_ok=True) # Ensure the source directory for historical data exists\n",
        "\n",
        "# Directly load historical data from the specified directory\n",
        "df = load_historical_csv(directory_path=\"/content/football data\")\n",
        "\n",
        "# Check if historical data was loaded successfully\n",
        "if not df.empty:\n",
        "    # Standardize column names after loading using a more robust approach\n",
        "    original_columns = df.columns.tolist()\n",
        "    df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
        "\n",
        "    # Mapping from *potential* original lowercase names to desired lowercase names\n",
        "    # This handles variations in spacing and capitalization in original CSVs\n",
        "    rename_map_lower = {\n",
        "        \"fthg\": \"fthg\", \"ftag\": \"ftag\", \"hs\": \"hs\", \"as\": \"as\", \"hst\": \"hst\",\n",
        "        \"ast\": \"ast\", \"hf\": \"hf\", \"af\": \"af\", \"hc\": \"hc\", \"ac\": \"ac\",\n",
        "        \"hy\": \"hy\", \"ay\": \"ay\", \"hr\": \"hr\", \"ar\": \"ar\", \"full_time_result\": \"result\",\n",
        "        \"hometeam\": \"home_team\", \"awayteam\": \"away_team\", \"date\": \"match_date\",\n",
        "        \"red_card\": \"ar\", \"yellow_card\": \"ay\", # Add mappings for common variations\n",
        "        # Add other potentially relevant columns from historical data if needed\n",
        "        # \"b365h\": \"b365h\", \"b365d\": \"b365d\", \"b365a\": \"b365a\", # Example betting odds\n",
        "    }\n",
        "\n",
        "    # Apply renaming based on the standardized lowercase column names\n",
        "    new_columns = {}\n",
        "    for col in df.columns:\n",
        "        # If the standardized column name is in our rename map, use the desired name\n",
        "        if col in rename_map_lower:\n",
        "            new_columns[col] = rename_map_lower[col]\n",
        "        else:\n",
        "            new_columns[col] = col # Keep the standardized name if not in map\n",
        "\n",
        "    df.rename(columns=new_columns, inplace=True)\n",
        "\n",
        "    print(\"ℹ️ Columns after standardization and renaming:\", df.columns.tolist()) # Debug print\n",
        "\n",
        "    # Convert date column to datetime\n",
        "    if \"match_date\" in df.columns:\n",
        "        # Attempt parsing with dayfirst=True, coerce errors\n",
        "        df[\"match_date\"] = pd.to_datetime(df[\"match_date\"], errors=\"coerce\", dayfirst=True)\n",
        "        # If still NaT values, try parsing without dayfirst\n",
        "        if df[\"match_date\"].isnull().any():\n",
        "             df[\"match_date\"] = pd.to_datetime(df[\"match_date\"], errors=\"coerce\")\n",
        "\n",
        "    # Create target variable (will use standardized fthg/ftag)\n",
        "    df = create_target(df)\n",
        "\n",
        "    # Check if target was created successfully before adding features and training\n",
        "    if \"result\" in df.columns and not df[\"result\"].isnull().all():\n",
        "        df = add_features(df)\n",
        "        model = train_model(df)\n",
        "    else:\n",
        "        print(\"❌ Target variable could not be created. Skipping model training.\")\n",
        "else:\n",
        "    print(\"❌ Historical data could not be loaded. Skipping further steps.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded E0(12).csv\n",
            "Loaded E0(23).csv\n",
            "Loaded E0(17).csv\n",
            "Loaded E0(14).csv\n",
            "Loaded E0(31).csv\n",
            "Loaded E0(26).csv\n",
            "Loaded E0(2).csv\n",
            "Loaded E0(15).csv\n",
            "Loaded E0(4).csv\n",
            "Loaded E0(30).csv\n",
            "Loaded E0(7).csv\n",
            "Loaded E0(18).csv\n",
            "Loaded E0(24).csv\n",
            "Loaded E0(32).csv\n",
            "Loaded E0(11).csv\n",
            "Loaded E0(10).csv\n",
            "Loaded E0(19).csv\n",
            "Loaded E0(1).csv\n",
            "Loaded E0(3).csv\n",
            "Loaded E0(20).csv\n",
            "Loaded E0(21).csv\n",
            "Loaded E0.csv\n",
            "Loaded E0(16).csv\n",
            "Loaded E0(8).csv\n",
            "Loaded E0(22).csv\n",
            "Loaded E0(29).csv\n",
            "Loaded E0(6).csv\n",
            "Loaded E0(25).csv\n",
            "Loaded E0(28).csv\n",
            "Loaded E0(5).csv\n",
            "Loaded E0(9).csv\n",
            "Loaded E0(13).csv\n",
            "Loaded E0(27).csv\n",
            "✅ All historical CSV files combined.\n",
            "ℹ️ Columns after standardization and renaming: ['div', 'match_date', 'home_team', 'away_team', 'fthg', 'ftag', 'ftr', 'hthg', 'htag', 'htr', 'referee', 'hs', 'as', 'hst', 'ast', 'hf', 'af', 'hc', 'ac', 'hy', 'ay', 'hr', 'ar', 'b365h', 'b365d', 'b365a', 'bwh', 'bwd', 'bwa', 'gbh', 'gbd', 'gba', 'iwh', 'iwd', 'iwa', 'lbh', 'lbd', 'lba', 'psh', 'psd', 'psa', 'whh', 'whd', 'wha', 'sjh', 'sjd', 'sja', 'vch', 'vcd', 'vca', 'bsh', 'bsd', 'bsa', 'bb1x2', 'bbmxh', 'bbavh', 'bbmxd', 'bbavd', 'bbmxa', 'bbava', 'bbou', 'bbmx>2.5', 'bbav>2.5', 'bbmx<2.5', 'bbav<2.5', 'bbah', 'bbahh', 'bbmxahh', 'bbavahh', 'bbmxaha', 'bbavaha', 'psch', 'pscd', 'psca', 'attendance', 'hhw', 'ahw', 'ho', 'ao', 'hbp', 'abp', 'sbh', 'sbd', 'sba', 'syh', 'syd', 'sya', 'unnamed:_7', 'unnamed:_8', 'unnamed:_9', 'unnamed:_10', 'unnamed:_11', 'unnamed:_12', 'unnamed:_13', 'unnamed:_14', 'unnamed:_15', 'unnamed:_16', 'unnamed:_17', 'unnamed:_18', 'unnamed:_19', 'unnamed:_20', 'unnamed:_21', 'unnamed:_22', 'unnamed:_23', 'unnamed:_24', 'unnamed:_25', 'unnamed:_26', 'unnamed:_27', 'time', 'maxh', 'maxd', 'maxa', 'avgh', 'avgd', 'avga', 'b365>2.5', 'b365<2.5', 'p>2.5', 'p<2.5', 'max>2.5', 'max<2.5', 'avg>2.5', 'avg<2.5', 'ahh', 'b365ahh', 'b365aha', 'pahh', 'paha', 'maxahh', 'maxaha', 'avgahh', 'avgaha', 'b365ch', 'b365cd', 'b365ca', 'bwch', 'bwcd', 'bwca', 'iwch', 'iwcd', 'iwca', 'whch', 'whcd', 'whca', 'vcch', 'vccd', 'vcca', 'maxch', 'maxcd', 'maxca', 'avgch', 'avgcd', 'avgca', 'b365c>2.5', 'b365c<2.5', 'pc>2.5', 'pc<2.5', 'maxc>2.5', 'maxc<2.5', 'avgc>2.5', 'avgc<2.5', 'ahch', 'b365cahh', 'b365caha', 'pcahh', 'pcaha', 'maxcahh', 'maxcaha', 'avgcahh', 'avgcaha', 'gb>2.5', 'gb<2.5', 'gbahh', 'gbaha', 'gbah', 'lbahh', 'lbaha', 'lbah', 'b365ah', 'soh', 'sod', 'soa', 'ï»¿div', 'bfh', 'bfd', 'bfa', '1xbh', '1xbd', '1xba', 'bfeh', 'bfed', 'bfea', 'bfe>2.5', 'bfe<2.5', 'bfeahh', 'bfeaha', 'bfch', 'bfcd', 'bfca', '1xbch', '1xbcd', '1xbca', 'bfech', 'bfecd', 'bfeca', 'bfec>2.5', 'bfec<2.5', 'bfecahh', 'bfecaha', 'unnamed:_48', 'unnamed:_49', 'unnamed:_50', 'unnamed:_51', 'unnamed:_52']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3801640094.py:211: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df[\"match_date\"] = pd.to_datetime(df[\"match_date\"], errors=\"coerce\", dayfirst=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ℹ️ Columns available in create_target: ['div', 'match_date', 'home_team', 'away_team', 'fthg', 'ftag', 'ftr', 'hthg', 'htag', 'htr', 'referee', 'hs', 'as', 'hst', 'ast', 'hf', 'af', 'hc', 'ac', 'hy', 'ay', 'hr', 'ar', 'b365h', 'b365d', 'b365a', 'bwh', 'bwd', 'bwa', 'gbh', 'gbd', 'gba', 'iwh', 'iwd', 'iwa', 'lbh', 'lbd', 'lba', 'psh', 'psd', 'psa', 'whh', 'whd', 'wha', 'sjh', 'sjd', 'sja', 'vch', 'vcd', 'vca', 'bsh', 'bsd', 'bsa', 'bb1x2', 'bbmxh', 'bbavh', 'bbmxd', 'bbavd', 'bbmxa', 'bbava', 'bbou', 'bbmx>2.5', 'bbav>2.5', 'bbmx<2.5', 'bbav<2.5', 'bbah', 'bbahh', 'bbmxahh', 'bbavahh', 'bbmxaha', 'bbavaha', 'psch', 'pscd', 'psca', 'attendance', 'hhw', 'ahw', 'ho', 'ao', 'hbp', 'abp', 'sbh', 'sbd', 'sba', 'syh', 'syd', 'sya', 'unnamed:_7', 'unnamed:_8', 'unnamed:_9', 'unnamed:_10', 'unnamed:_11', 'unnamed:_12', 'unnamed:_13', 'unnamed:_14', 'unnamed:_15', 'unnamed:_16', 'unnamed:_17', 'unnamed:_18', 'unnamed:_19', 'unnamed:_20', 'unnamed:_21', 'unnamed:_22', 'unnamed:_23', 'unnamed:_24', 'unnamed:_25', 'unnamed:_26', 'unnamed:_27', 'time', 'maxh', 'maxd', 'maxa', 'avgh', 'avgd', 'avga', 'b365>2.5', 'b365<2.5', 'p>2.5', 'p<2.5', 'max>2.5', 'max<2.5', 'avg>2.5', 'avg<2.5', 'ahh', 'b365ahh', 'b365aha', 'pahh', 'paha', 'maxahh', 'maxaha', 'avgahh', 'avgaha', 'b365ch', 'b365cd', 'b365ca', 'bwch', 'bwcd', 'bwca', 'iwch', 'iwcd', 'iwca', 'whch', 'whcd', 'whca', 'vcch', 'vccd', 'vcca', 'maxch', 'maxcd', 'maxca', 'avgch', 'avgcd', 'avgca', 'b365c>2.5', 'b365c<2.5', 'pc>2.5', 'pc<2.5', 'maxc>2.5', 'maxc<2.5', 'avgc>2.5', 'avgc<2.5', 'ahch', 'b365cahh', 'b365caha', 'pcahh', 'pcaha', 'maxcahh', 'maxcaha', 'avgcahh', 'avgcaha', 'gb>2.5', 'gb<2.5', 'gbahh', 'gbaha', 'gbah', 'lbahh', 'lbaha', 'lbah', 'b365ah', 'soh', 'sod', 'soa', 'ï»¿div', 'bfh', 'bfd', 'bfa', '1xbh', '1xbd', '1xba', 'bfeh', 'bfed', 'bfea', 'bfe>2.5', 'bfe<2.5', 'bfeahh', 'bfeaha', 'bfch', 'bfcd', 'bfca', '1xbch', '1xbcd', '1xbca', 'bfech', 'bfecd', 'bfeca', 'bfec>2.5', 'bfec<2.5', 'bfecahh', 'bfecaha', 'unnamed:_48', 'unnamed:_49', 'unnamed:_50', 'unnamed:_51', 'unnamed:_52']\n",
            "✅ Target variable 'result' created based on historical data.\n",
            "ℹ️ Columns available in add_features: ['div', 'match_date', 'home_team', 'away_team', 'fthg', 'ftag', 'ftr', 'hthg', 'htag', 'htr', 'referee', 'hs', 'as', 'hst', 'ast', 'hf', 'af', 'hc', 'ac', 'hy', 'ay', 'hr', 'ar', 'b365h', 'b365d', 'b365a', 'bwh', 'bwd', 'bwa', 'gbh', 'gbd', 'gba', 'iwh', 'iwd', 'iwa', 'lbh', 'lbd', 'lba', 'psh', 'psd', 'psa', 'whh', 'whd', 'wha', 'sjh', 'sjd', 'sja', 'vch', 'vcd', 'vca', 'bsh', 'bsd', 'bsa', 'bb1x2', 'bbmxh', 'bbavh', 'bbmxd', 'bbavd', 'bbmxa', 'bbava', 'bbou', 'bbmx>2.5', 'bbav>2.5', 'bbmx<2.5', 'bbav<2.5', 'bbah', 'bbahh', 'bbmxahh', 'bbavahh', 'bbmxaha', 'bbavaha', 'psch', 'pscd', 'psca', 'attendance', 'hhw', 'ahw', 'ho', 'ao', 'hbp', 'abp', 'sbh', 'sbd', 'sba', 'syh', 'syd', 'sya', 'unnamed:_7', 'unnamed:_8', 'unnamed:_9', 'unnamed:_10', 'unnamed:_11', 'unnamed:_12', 'unnamed:_13', 'unnamed:_14', 'unnamed:_15', 'unnamed:_16', 'unnamed:_17', 'unnamed:_18', 'unnamed:_19', 'unnamed:_20', 'unnamed:_21', 'unnamed:_22', 'unnamed:_23', 'unnamed:_24', 'unnamed:_25', 'unnamed:_26', 'unnamed:_27', 'time', 'maxh', 'maxd', 'maxa', 'avgh', 'avgd', 'avga', 'b365>2.5', 'b365<2.5', 'p>2.5', 'p<2.5', 'max>2.5', 'max<2.5', 'avg>2.5', 'avg<2.5', 'ahh', 'b365ahh', 'b365aha', 'pahh', 'paha', 'maxahh', 'maxaha', 'avgahh', 'avgaha', 'b365ch', 'b365cd', 'b365ca', 'bwch', 'bwcd', 'bwca', 'iwch', 'iwcd', 'iwca', 'whch', 'whcd', 'whca', 'vcch', 'vccd', 'vcca', 'maxch', 'maxcd', 'maxca', 'avgch', 'avgcd', 'avgca', 'b365c>2.5', 'b365c<2.5', 'pc>2.5', 'pc<2.5', 'maxc>2.5', 'maxc<2.5', 'avgc>2.5', 'avgc<2.5', 'ahch', 'b365cahh', 'b365caha', 'pcahh', 'pcaha', 'maxcahh', 'maxcaha', 'avgcahh', 'avgcaha', 'gb>2.5', 'gb<2.5', 'gbahh', 'gbaha', 'gbah', 'lbahh', 'lbaha', 'lbah', 'b365ah', 'soh', 'sod', 'soa', 'ï»¿div', 'bfh', 'bfd', 'bfa', '1xbh', '1xbd', '1xba', 'bfeh', 'bfed', 'bfea', 'bfe>2.5', 'bfe<2.5', 'bfeahh', 'bfeaha', 'bfch', 'bfcd', 'bfca', '1xbch', '1xbcd', '1xbca', 'bfech', 'bfecd', 'bfeca', 'bfec>2.5', 'bfec<2.5', 'bfecahh', 'bfecaha', 'unnamed:_48', 'unnamed:_49', 'unnamed:_50', 'unnamed:_51', 'unnamed:_52', 'result']\n",
            "ℹ️ Using 'fthg' and 'ftag' for goal calculations.\n",
            "✅ 'home_goal_diff' and 'away_goal_diff' features created.\n",
            "ℹ️ Columns available in train_model: ['div', 'match_date', 'home_team', 'away_team', 'fthg', 'ftag', 'ftr', 'hthg', 'htag', 'htr', 'referee', 'hs', 'as', 'hst', 'ast', 'hf', 'af', 'hc', 'ac', 'hy', 'ay', 'hr', 'ar', 'b365h', 'b365d', 'b365a', 'bwh', 'bwd', 'bwa', 'gbh', 'gbd', 'gba', 'iwh', 'iwd', 'iwa', 'lbh', 'lbd', 'lba', 'psh', 'psd', 'psa', 'whh', 'whd', 'wha', 'sjh', 'sjd', 'sja', 'vch', 'vcd', 'vca', 'bsh', 'bsd', 'bsa', 'bb1x2', 'bbmxh', 'bbavh', 'bbmxd', 'bbavd', 'bbmxa', 'bbava', 'bbou', 'bbmx>2.5', 'bbav>2.5', 'bbmx<2.5', 'bbav<2.5', 'bbah', 'bbahh', 'bbmxahh', 'bbavahh', 'bbmxaha', 'bbavaha', 'psch', 'pscd', 'psca', 'attendance', 'hhw', 'ahw', 'ho', 'ao', 'hbp', 'abp', 'sbh', 'sbd', 'sba', 'syh', 'syd', 'sya', 'unnamed:_7', 'unnamed:_8', 'unnamed:_9', 'unnamed:_10', 'unnamed:_11', 'unnamed:_12', 'unnamed:_13', 'unnamed:_14', 'unnamed:_15', 'unnamed:_16', 'unnamed:_17', 'unnamed:_18', 'unnamed:_19', 'unnamed:_20', 'unnamed:_21', 'unnamed:_22', 'unnamed:_23', 'unnamed:_24', 'unnamed:_25', 'unnamed:_26', 'unnamed:_27', 'time', 'maxh', 'maxd', 'maxa', 'avgh', 'avgd', 'avga', 'b365>2.5', 'b365<2.5', 'p>2.5', 'p<2.5', 'max>2.5', 'max<2.5', 'avg>2.5', 'avg<2.5', 'ahh', 'b365ahh', 'b365aha', 'pahh', 'paha', 'maxahh', 'maxaha', 'avgahh', 'avgaha', 'b365ch', 'b365cd', 'b365ca', 'bwch', 'bwcd', 'bwca', 'iwch', 'iwcd', 'iwca', 'whch', 'whcd', 'whca', 'vcch', 'vccd', 'vcca', 'maxch', 'maxcd', 'maxca', 'avgch', 'avgcd', 'avgca', 'b365c>2.5', 'b365c<2.5', 'pc>2.5', 'pc<2.5', 'maxc>2.5', 'maxc<2.5', 'avgc>2.5', 'avgc<2.5', 'ahch', 'b365cahh', 'b365caha', 'pcahh', 'pcaha', 'maxcahh', 'maxcaha', 'avgcahh', 'avgcaha', 'gb>2.5', 'gb<2.5', 'gbahh', 'gbaha', 'gbah', 'lbahh', 'lbaha', 'lbah', 'b365ah', 'soh', 'sod', 'soa', 'ï»¿div', 'bfh', 'bfd', 'bfa', '1xbh', '1xbd', '1xba', 'bfeh', 'bfed', 'bfea', 'bfe>2.5', 'bfe<2.5', 'bfeahh', 'bfeaha', 'bfch', 'bfcd', 'bfca', '1xbch', '1xbcd', '1xbca', 'bfech', 'bfecd', 'bfeca', 'bfec>2.5', 'bfec<2.5', 'bfecahh', 'bfecaha', 'unnamed:_48', 'unnamed:_49', 'unnamed:_50', 'unnamed:_51', 'unnamed:_52', 'result', 'home_goal_diff', 'away_goal_diff']\n",
            "Using features: ['hs', 'as', 'hst', 'ast', 'hf', 'af', 'hc', 'ac', 'hy', 'ay', 'hr', 'ar', 'home_goal_diff', 'away_goal_diff']\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       1.00      1.00      1.00       725\n",
            "           0       1.00      1.00      1.00       815\n",
            "           1       1.00      1.00      1.00      1157\n",
            "\n",
            "    accuracy                           1.00      2697\n",
            "   macro avg       1.00      1.00      1.00      2697\n",
            "weighted avg       1.00      1.00      1.00      2697\n",
            "\n",
            "✅ Model and scaler saved successfully!\n"
          ]
        }
      ]
    }
  ]
}